# import os
# import pdfplumber
# import requests
# import time
# from dotenv import load_dotenv
# from bs4 import BeautifulSoup
# from langchain_community.vectorstores import FAISS
# from langchain_openai import OpenAIEmbeddings
# from langchain_text_splitters import RecursiveCharacterTextSplitter
# from langchain.prompts import ChatPromptTemplate
# from langchain_openai import ChatOpenAI
# from langchain.tools import Tool
# from langchain_core.documents import Document
# from langchain.schema import AIMessage, HumanMessage

# # Load environment variables
# load_dotenv()

# # Set OpenAI API Key
# os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')

# # User-Agent Header to Avoid Bot Detection
# headers = {
#     "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
#     "Accept-Language": "en-US,en;q=0.9",
#     "Referer": "https://www.google.com/",
#     "DNT": "1",
#     "Connection": "keep-alive"
# }

# # Website URLs
# urls = [
#     "https://www.which.co.uk/money/mortgages-and-property/mortgages",
#     "https://money.co.uk/mortgages/a-complete-guide-to-mortgages",
#     "https://citizensadvice.org.uk/debt-and-money/mortgage-problems/",
#     "https://experian.co.uk/consumer/mortgages/guides/what-is-a-mortgage.html",
#     "https://which.co.uk/money/mortgages-and-property/mortgages/types-of-mortgage/mortgage-types-explained-aIGHA3F2WqyQ"
# ]

# # Function to Extract Text from a PDF
# def extract_text_from_pdf(pdf_path):
#     if not os.path.exists(pdf_path):
#         return "No PDF file found."
    
#     text = ""
#     try:
#         with pdfplumber.open(pdf_path) as pdf:
#             for page in pdf.pages:
#                 extracted_text = page.extract_text()
#                 if extracted_text:
#                     text += extracted_text + "\n"
#     except Exception:
#         return "No text extracted from PDF."
    
#     return text.strip() if text else "No text extracted from PDF."

# # Set PDF Path
# pdf_path = r"C:\Users\STA\Desktop\KFV\AI Mortgage Advisor Project-12345.pdf"
# pdf_docs_text = extract_text_from_pdf(pdf_path)

# # Function to Scrape and Clean Website Data
# def scrape_website(url):
#     try:
#         time.sleep(3)  # Avoid bot detection
#         response = requests.get(url, headers=headers, timeout=10)
        
#         if response.status_code == 200:
#             soup = BeautifulSoup(response.text, "html.parser")
            
#             # Remove footer, navigation, and legal text
#             for tag in soup.find_all(["footer", "nav", "script", "style", "header", "aside"]):
#                 tag.extract()
            
#             text_content = soup.get_text(separator=" ", strip=True)
#             return text_content
#         return None
#     except Exception:
#         return None

# # Scrape and Clean Website Data
# docs = [scrape_website(url) for url in urls if scrape_website(url)]

# # Combine Scraped Web Content and PDF Content
# all_docs = [Document(page_content=doc) for doc in docs] + [Document(page_content=pdf_docs_text)]

# # Split Documents into Smaller Chunks
# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
# documents = text_splitter.split_documents(all_docs)

# # Create FAISS Vector Store for Retrieval
# vectordb = FAISS.from_documents(documents, OpenAIEmbeddings())
# retriever = vectordb.as_retriever(search_kwargs={"k": 5})  # Get top 5 most relevant chunks

# # Initialize ChatOpenAI Model
# llm = ChatOpenAI(model="gpt-4", temperature=0.7, max_tokens=2000, top_p=0.9)

# # Mortgage-related keywords to detect mortgage questions
# mortgage_keywords = [
#     "mortgage", "home loan", "property", "house", "buy", "purchase", "interest rate", 
#     "down payment", "deposit", "first-time buyer", "fixed rate", "variable rate", 
#     "remortgage", "equity", "repayment", "loan-to-value", "ltv", "term", "lender",
#     "borrowing", "credit score", "affordability", "amortization", "foreclosure",
#     "capital", "conveyancing", "stamp duty", "equity release", "tracker", "offset"
# ]

# # Predefined Questions for detailed mortgage application
# predefined_questions = [
#     "Is this a single person application or are you a partnership? i.e married, civil partnership or living together.",
#     "Are you a first-time buyer?",
#     "Please can you give me your date of birth and your partner's, if applicable.",
#     "Are you in employment?",
#     "If yes, please specify if you are employed or self-employed?",
#     "How much do you earn per year, gross pay before tax and NI, also include any commission, bonus, overtime and any other income sources.",
#     "Please can you tell me if you have any credit commitments, if yes please list them, examples are credit cards, loans or even other mortgage payments and pensions.",
#     "How many dependants do you have, if any?",
#     "If you have adverse credit, please tell me what it is?",
#     "Do you have an existing property that you plan to sell to support your new mortgage? If yes â€“ what is it worth, how much do you have outstanding on the mortgage and what do you hope to sell it for?",
#     "Finally, what is your committed expenditure. Examples are maintenance, school fees & nursery costs."
# ]

# # Trigger Phrases for full mortgage application
# trigger_phrases = [
#     "I want to buy a house",
#     "I need a home loan",
#     "I want to apply for a mortgage",
#     "Can you help me get a mortgage",
#     "I need a mortgage for my new property",
#     "help me apply for a mortgage"
# ]

# # Function to Check if User Input Contains Mortgage Keywords
# def is_mortgage_related(input_text):
#     input_text = input_text.lower()
    
#     # Check for trigger phrases (full application)
#     for phrase in trigger_phrases:
#         if phrase.lower() in input_text:
#             return "application"
    
#     # Check for mortgage keywords (informational)
#     for keyword in mortgage_keywords:
#         if keyword.lower() in input_text:
#             return "information"
            
#     return "general"

# # Function to Retrieve Relevant Information from Vector Database
# def get_relevant_info(query):
#     try:
#         # Get relevant documents from vector database
#         relevant_docs = retriever.invoke(query)
        
#         # Extract and format the content
#         retrieved_info = "\n\n".join([doc.page_content for doc in relevant_docs])
#         return retrieved_info
#     except Exception as e:
#         print(f"Error retrieving information: {e}")
#         return ""

# # Function to Ask Predefined Questions
# def ask_predefined_questions():
#     user_responses = {}
#     for question in predefined_questions:
#         print(f"\nðŸ¤– AI: {question}")
#         user_response = input("Your answer: ").strip()
#         user_responses[question] = user_response
#     return user_responses

# # Function to Generate Response Using Retrieval-Augmented Generation
# def generate_rag_response(user_input):
#     # Get relevant information from vector database
#     relevant_info = get_relevant_info(user_input)
    
#     # Create a prompt that includes the retrieved information
#     rag_prompt = f"""
#     You are a knowledgeable mortgage advisor with expertise in UK mortgages, home loans, and property financing.
    
#     Relevant information from our knowledge base:
#     {relevant_info}
    
#     User's question: {user_input}
    
#     Based on the relevant information provided above, please give a comprehensive, detailed, and informative answer to the user's question.
#     Include specific details like typical interest rates, down payment percentages, loan terms, or requirements when relevant.
#     Structure your answer with clear sections and examples when appropriate.
#     If the information is not available in the knowledge base, provide general mortgage advice but be honest about limitations.
#     """
    
#     # Generate response using the model with RAG
#     response = llm.invoke([HumanMessage(content=rag_prompt)])
#     return response.content

# # Function to Generate Summary Using the Model
# def generate_summary(user_responses):
#     # Combine questions and answers into a single string
#     qa_pairs = "\n".join([f"Q: {q}\nA: {a}" for q, a in user_responses.items()])
    
#     # Prompt for the model to generate a summary
#     summary_prompt = f"""
#     You are a helpful mortgage advisor. Below are the questions and answers provided by the user. 
#     Please summarize the information in a clear and concise way, and provide any relevant advice or next steps.

#     Questions and Answers:
#     {qa_pairs}

#     Summary:
#     """
    
#     # Generate summary using the model
#     summary_response = llm.invoke([HumanMessage(content=summary_prompt)])
#     return summary_response.content

# # Chat Memory Storage
# chat_history = []

# # Chatbot Interaction
# print("\nðŸš€ Welcome! Your AI Mortgage Advisor is ready. Ask me anything!")

# chat_active = True
# user_data = {}
# last_message = ""

# while chat_active:
#     user_input = input("\nYour message: ").strip()
    
#     if not user_input:
#         continue  # Skip empty input
    
#     if user_input.lower() in ["exit", "quit", "close"]:
#         print("âœ… Thank you for chatting! It was great talking to you. Have a wonderful day! ðŸ˜Š")
#         break  # Exit the chat
    
#     # Prevent duplicate messages
#     if user_input == last_message:
#         continue
#     last_message = user_input
    
#     # Check what type of query this is
#     query_type = is_mortgage_related(user_input)
    
#     # Handle based on query type
#     if query_type == "application":
#         # Full mortgage application process
#         print("\nðŸ¤– AI: Sure! I can help you with your mortgage application. Let me ask you a few questions to get started.")
#         user_data = ask_predefined_questions()
        
#         # Generate Summary Using the Model
#         print("\nðŸ¤– AI: Thank you for providing the information! Generating a summary for you...")
#         summary = generate_summary(user_data)
        
#         # Display Summary to the User
#         print(f"\nðŸ¤– AI: Here's a summary based on your answers:\n{summary}")
        
#         # Ask if they want to continue or exit
#         print("\nðŸ¤– AI: Would you like to continue chatting or exit? (Type 'continue' or 'exit')")
#         continue_choice = input("Your choice: ").strip().lower()
#         if continue_choice == "exit":
#             print("âœ… Thank you for chatting! It was great talking to you. Have a wonderful day! ðŸ˜Š")
#             break
    
#     elif query_type == "information":
#         # Mortgage information query - use RAG
#         response_text = generate_rag_response(user_input)
        
#         chat_history.append(HumanMessage(content=user_input))
#         chat_history.append(AIMessage(content=response_text))
        
#         print(f"\nðŸ¤– AI: {response_text}")
    
#     else:
#         # General chatbot interaction
#         general_prompt = f"You are a friendly and engaging mortgage advisor. Respond naturally and conversationally like a human. Here's the user's message: '{user_input}'"
#         general_response = llm.invoke([HumanMessage(content=general_prompt)])
#         response_text = general_response.content
        
#         chat_history.append(HumanMessage(content=user_input))
#         chat_history.append(AIMessage(content=response_text))
        
#         print(f"\nðŸ¤– AI: {response_text}")




# import os
# import pdfplumber
# import requests
# import time
# from dotenv import load_dotenv
# from bs4 import BeautifulSoup
# from langchain_community.vectorstores import FAISS
# from langchain_openai import OpenAIEmbeddings
# from langchain_text_splitters import RecursiveCharacterTextSplitter
# from langchain.prompts import ChatPromptTemplate
# from langchain_openai import ChatOpenAI
# from langchain.tools import Tool
# from langchain_core.documents import Document
# from langchain.schema import AIMessage, HumanMessage

# # Load environment variables
# load_dotenv()

# # Set OpenAI API Key
# os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')

# # User-Agent Header to Avoid Bot Detection
# headers = {
#     "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
#     "Accept-Language": "en-US,en;q=0.9",
#     "Referer": "https://www.google.com/",
#     "DNT": "1",
#     "Connection": "keep-alive"
# }

# # Website URLs
# urls = [
#     "https://www.which.co.uk/money/mortgages-and-property/mortgages",
#     "https://money.co.uk/mortgages/a-complete-guide-to-mortgages",
#     "https://citizensadvice.org.uk/debt-and-money/mortgage-problems/",
#     "https://experian.co.uk/consumer/mortgages/guides/what-is-a-mortgage.html",
#     "https://which.co.uk/money/mortgages-and-property/mortgages/types-of-mortgage/mortgage-types-explained-aIGHA3F2WqyQ"
# ]

# # Function to Extract Text from a PDF
# def extract_text_from_pdf(pdf_path):
#     if not os.path.exists(pdf_path):
#         return "No PDF file found."
    
#     text = ""
#     try:
#         with pdfplumber.open(pdf_path) as pdf:
#             for page in pdf.pages:
#                 extracted_text = page.extract_text()
#                 if extracted_text:
#                     text += extracted_text + "\n"
#     except Exception:
#         return "No text extracted from PDF."
    
#     return text.strip() if text else "No text extracted from PDF."

# # Set PDF Path
# pdf_path = r"C:\Users\STA\Desktop\KFV\AI Mortgage Advisor Project-12345.pdf"
# pdf_docs_text = extract_text_from_pdf(pdf_path)

# # Function to Scrape and Clean Website Data
# def scrape_website(url):
#     try:
#         time.sleep(3)  # Avoid bot detection
#         response = requests.get(url, headers=headers, timeout=10)
        
#         if response.status_code == 200:
#             soup = BeautifulSoup(response.text, "html.parser")
            
#             # Remove footer, navigation, and legal text
#             for tag in soup.find_all(["footer", "nav", "script", "style", "header", "aside"]):
#                 tag.extract()
            
#             text_content = soup.get_text(separator=" ", strip=True)
#             return text_content
#         return None
#     except Exception:
#         return None

# # Scrape and Clean Website Data
# docs = [scrape_website(url) for url in urls if scrape_website(url)]

# # Combine Scraped Web Content and PDF Content
# all_docs = [Document(page_content=doc) for doc in docs] + [Document(page_content=pdf_docs_text)]

# # Split Documents into Smaller Chunks
# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
# documents = text_splitter.split_documents(all_docs)

# # Create FAISS Vector Store for Retrieval
# vectordb = FAISS.from_documents(documents, OpenAIEmbeddings())
# retriever = vectordb.as_retriever(search_kwargs={"k": 5})  # Get top 5 most relevant chunks

# # Initialize ChatOpenAI Model
# llm = ChatOpenAI(model="gpt-4", temperature=1.0, max_tokens=2000, top_p=0.9)

# # Mortgage-related keywords to detect mortgage questions
# mortgage_keywords = [
#     "mortgage", "home loan", "property", "house", "buy", "purchase", "interest rate", 
#     "down payment", "deposit", "first-time buyer", "fixed rate", "variable rate", 
#     "remortgage", "equity", "repayment", "loan-to-value", "ltv", "term", "lender",
#     "borrowing", "credit score", "affordability", "amortization", "foreclosure",
#     "capital", "conveyancing", "stamp duty", "equity release", "tracker", "offset"
# ]

# # Predefined Questions for detailed mortgage application
# predefined_questions = [
#     "Is this a single person application or are you a partnership? i.e married, civil partnership or living together.",
#     "Are you a first-time buyer?",
#     "Please can you give me your date of birth and your partner's, if applicable.",
#     "Are you in employment?",
#     "If yes, please specify if you are employed or self-employed?",
#     "How much do you earn per year, gross pay before tax and NI, also include any commission, bonus, overtime and any other income sources.",
#     "Please can you tell me if you have any credit commitments, if yes please list them, examples are credit cards, loans or even other mortgage payments and pensions.",
#     "How many dependants do you have, if any?",
#     "If you have adverse credit, please tell me what it is?",
#     "Do you have an existing property that you plan to sell to support your new mortgage? If yes â€“ what is it worth, how much do you have outstanding on the mortgage and what do you hope to sell it for?",
#     "Finally, what is your committed expenditure. Examples are maintenance, school fees & nursery costs."
# ]

# # Trigger Phrases for full mortgage application
# trigger_phrases = [
#     "I want to buy a house",
#     "I need a home loan",
#     "I want to apply for a mortgage",
#     "Can you help me get a mortgage",
#     "I need a mortgage for my new property",
#     "help me apply for a mortgage"
# ]

# # Function to Check if User Input Contains Mortgage Keywords
# def is_mortgage_related(input_text):
#     input_text = input_text.lower()
    
#     # Check for trigger phrases (full application)
#     for phrase in trigger_phrases:
#         if phrase.lower() in input_text:
#             return "application"
    
#     # Check for mortgage keywords (informational)
#     for keyword in mortgage_keywords:
#         if keyword.lower() in input_text:
#             return "information"
            
#     return "general"

# # Function to Retrieve Relevant Information from Vector Database
# def get_relevant_info(query):
#     try:
#         # Get relevant documents from vector database
#         relevant_docs = retriever.invoke(query)
        
#         # Extract and format the content
#         retrieved_info = "\n\n".join([doc.page_content for doc in relevant_docs])
#         return retrieved_info
#     except Exception as e:
#         print(f"Error retrieving information: {e}")
#         return ""

# # Function to Ask Predefined Questions
# def ask_predefined_questions():
#     user_responses = {}
#     for question in predefined_questions:
#         print(f"\nðŸ¤– AI: {question}")
#         user_response = input("Your answer: ").strip()
#         user_responses[question] = user_response
#     return user_responses

# # Function to Generate Response Using Retrieval-Augmented Generation
# def generate_rag_response(user_input):
#     # Get relevant information from vector database
#     relevant_info = get_relevant_info(user_input)
    
#     # Create a prompt that includes the retrieved information
#     rag_prompt = f"""
#     You are a knowledgeable mortgage advisor with expertise in UK mortgages, home loans, and property financing.
    
#     Relevant information from our knowledge base:
#     {relevant_info}
    
#     User's question: {user_input}
    
#     Based on the relevant information provided above, please give a comprehensive, detailed, and informative answer to the user's question.
#     Include specific details like typical interest rates, down payment percentages, loan terms, or requirements when relevant.
#     Structure your answer with clear sections and examples when appropriate.
#     If the information is not available in the knowledge base, provide general mortgage advice but be honest about limitations.
#     """
    
#     # Generate response using the model with RAG
#     response = llm.invoke([HumanMessage(content=rag_prompt)])
#     return response.content

# # Function to Generate Summary Using the Model
# def generate_summary(user_responses):
#     # Combine questions and answers into a prompt for the model
#     qa_pairs = "\n".join([f"Q: {q}\nA: {a}" for q, a in user_responses.items()])
    
#     # Prompt for the model to generate a summary
#     summary_prompt = f"""
#     You are a helpful mortgage advisor. Below are the questions and answers provided by the user. 
#     Please summarize the information in a clear and concise way, and provide any relevant advice or next steps.

#     Questions and Answers:
#     {qa_pairs}

#     Summary:
#     """
    
#     # Generate summary using the model
#     summary_response = llm.invoke([HumanMessage(content=summary_prompt)])
#     return summary_response.content

# # Chat Memory Storage
# chat_history = []

# # Chatbot Interaction
# print("\nðŸš€ Welcome! Your AI Mortgage Advisor is ready. Ask me anything!")

# chat_active = True
# user_data = {}
# last_message = ""

# while chat_active:
#     user_input = input("\nYour message: ").strip()
    
#     if not user_input:
#         continue  # Skip empty input
    
#     if user_input.lower() in ["exit", "quit", "close"]:
#         print("âœ… Thank you for chatting! It was great talking to you. Have a wonderful day! ðŸ˜Š")
#         break  # Exit the chat
    
#     # Prevent duplicate messages
#     if user_input == last_message:
#         continue
#     last_message = user_input
    
#     # Check what type of query this is
#     query_type = is_mortgage_related(user_input)
    
#     # Handle based on query type
#     if query_type == "application":
#         # Full mortgage application process
#         print("\nðŸ¤– AI: Sure! I can help you with your mortgage application. Let me ask you a few questions to get started.")
#         user_data = ask_predefined_questions()
        
#         # Generate Summary Using the Model
#         print("\nðŸ¤– AI: Thank you for providing the information! Generating a summary for you...")
#         summary = generate_summary(user_data)
        
#         # Display Summary to the User
#         print(f"\nðŸ¤– AI: Here's a summary based on your answers:\n{summary}")
        
#         # Ask if they want to continue or exit
#         print("\nðŸ¤– AI: Would you like to continue chatting or exit? (Type 'continue' or 'exit')")
#         continue_choice = input("Your choice: ").strip().lower()
#         if continue_choice == "exit":
#             print("âœ… Thank you for chatting! It was great talking to you. Have a wonderful day! ðŸ˜Š")
#             break
    
#     elif query_type == "information":
#         # Mortgage information query - use RAG
#         response_text = generate_rag_response(user_input)
        
#         chat_history.append(HumanMessage(content=user_input))
#         chat_history.append(AIMessage(content=response_text))
        
#         print(f"\nðŸ¤– AI: {response_text}")
    
#     else:
#         # General chatbot interaction
#         general_prompt = f"You are a friendly and engaging mortgage advisor. Respond naturally and conversationally like a human. Here's the user's message: '{user_input}'"
#         general_response = llm.invoke([HumanMessage(content=general_prompt)])
#         response_text = general_response.content
        
#         chat_history.append(HumanMessage(content=user_input))
#         chat_history.append(AIMessage(content=response_text))
        
#         print(f"\nðŸ¤– AI: {response_text}")





# import os
# import pdfplumber
# import requests
# import time
# from dotenv import load_dotenv
# from bs4 import BeautifulSoup
# from langchain_community.vectorstores import FAISS
# from langchain_openai import OpenAIEmbeddings
# from langchain_text_splitters import RecursiveCharacterTextSplitter
# from langchain.prompts import ChatPromptTemplate
# from langchain_openai import ChatOpenAI
# from langchain.tools import Tool
# from langchain_core.documents import Document
# from langchain.schema import AIMessage, HumanMessage

# # Load environment variables
# load_dotenv()

# # Set OpenAI API Key
# os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')

# # User-Agent Header to Avoid Bot Detection
# headers = {
#     "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
#     "Accept-Language": "en-US,en;q=0.9",
#     "Referer": "https://www.google.com/",
#     "DNT": "1",
#     "Connection": "keep-alive"
# }

# # Website URLs
# urls = [
#     "https://www.which.co.uk/money/mortgages-and-property/mortgages",
#     "https://money.co.uk/mortgages/a-complete-guide-to-mortgages",
#     "https://citizensadvice.org.uk/debt-and-money/mortgage-problems/",
#     "https://experian.co.uk/consumer/mortgages/guides/what-is-a-mortgage.html",
#     "https://which.co.uk/money/mortgages-and-property/mortgages/types-of-mortgage/mortgage-types-explained-aIGHA3F2WqyQ"
# ]

# # Function to Extract Text from a PDF
# def extract_text_from_pdf(pdf_path):
#     if not os.path.exists(pdf_path):
#         return "No PDF file found."
    
#     text = ""
#     try:
#         with pdfplumber.open(pdf_path) as pdf:
#             for page in pdf.pages:
#                 extracted_text = page.extract_text()
#                 if extracted_text:
#                     text += extracted_text + "\n"
#     except Exception:
#         return "No text extracted from PDF."
    
#     return text.strip() if text else "No text extracted from PDF."

# # Set PDF Path
# pdf_path = r"C:\Users\STA\Desktop\KFV\AI Mortgage Advisor Project-12345.pdf"
# pdf_docs_text = extract_text_from_pdf(pdf_path)

# # Function to Scrape and Clean Website Data
# def scrape_website(url):
#     try:
#         time.sleep(3)  # Avoid bot detection
#         response = requests.get(url, headers=headers, timeout=10)
        
#         if response.status_code == 200:
#             soup = BeautifulSoup(response.text, "html.parser")
            
#             # Remove footer, navigation, and legal text
#             for tag in soup.find_all(["footer", "nav", "script", "style", "header", "aside"]):
#                 tag.extract()
            
#             text_content = soup.get_text(separator=" ", strip=True)
#             return text_content
#         return None
#     except Exception:
#         return None

# # Scrape and Clean Website Data
# docs = [scrape_website(url) for url in urls if scrape_website(url)]

# # Combine Scraped Web Content and PDF Content
# all_docs = [Document(page_content=doc) for doc in docs] + [Document(page_content=pdf_docs_text)]

# # Split Documents into Smaller Chunks
# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
# documents = text_splitter.split_documents(all_docs)

# # Create FAISS Vector Store for Retrieval
# vectordb = FAISS.from_documents(documents, OpenAIEmbeddings())
# retriever = vectordb.as_retriever(search_kwargs={"k": 5})  # Get top 5 most relevant chunks

# # Initialize ChatOpenAI Model
# llm = ChatOpenAI(model="gpt-4", temperature=0.7, max_tokens=2000, top_p=0.9)

# # Mortgage-related keywords to detect mortgage questions
# mortgage_keywords = [
#     "mortgage", "home loan", "property", "house", "buy", "purchase", "interest rate", 
#     "down payment", "deposit", "first-time buyer", "fixed rate", "variable rate", 
#     "remortgage", "equity", "repayment", "loan-to-value", "ltv", "term", "lender",
#     "borrowing", "credit score", "affordability", "amortization", "foreclosure",
#     "capital", "conveyancing", "stamp duty", "equity release", "tracker", "offset"
# ]

# # Predefined Questions for detailed mortgage application
# predefined_questions = [
#     "Is this a single person application or are you a partnership? i.e married, civil partnership or living together.",
#     "Are you a first-time buyer?",
#     "Please can you give me your date of birth and your partner's, if applicable.",
#     "Are you in employment?",
#     "If yes, please specify if you are employed or self-employed?",
#     "How much do you earn per year, gross pay before tax and NI, also include any commission, bonus, overtime and any other income sources.",
#     "Please can you tell me if you have any credit commitments, if yes please list them, examples are credit cards, loans or even other mortgage payments and pensions.",
#     "How many dependants do you have, if any?",
#     "If you have adverse credit, please tell me what it is?",
#     "Do you have an existing property that you plan to sell to support your new mortgage? If yes â€“ what is it worth, how much do you have outstanding on the mortgage and what do you hope to sell it for?",
#     "Finally, what is your committed expenditure. Examples are maintenance, school fees & nursery costs."
# ]

# # Trigger Phrases for full mortgage application
# trigger_phrases = [
#     "I want to buy a house",
#     "I need a home loan",
#     "I want to apply for a mortgage",
#     "Can you help me get a mortgage",
#     "I need a mortgage for my new property",
#     "help me apply for a mortgage"
# ]

# # Function to Check if User Input Contains Mortgage Keywords
# def is_mortgage_related(input_text):
#     input_text = input_text.lower()
    
#     # Check for trigger phrases (full application)
#     for phrase in trigger_phrases:
#         if phrase.lower() in input_text:
#             return "application"
    
#     # Check for mortgage keywords (informational)
#     for keyword in mortgage_keywords:
#         if keyword.lower() in input_text:
#             return "information"
            
#     return "general"

# # Function to Retrieve Relevant Information from Vector Database
# def get_relevant_info(query):
#     try:
#         # Get relevant documents from vector database
#         relevant_docs = retriever.invoke(query)
        
#         # Extract and format the content
#         retrieved_info = "\n\n".join([doc.page_content for doc in relevant_docs])
#         return retrieved_info
#     except Exception as e:
#         print(f"Error retrieving information: {e}")
#         return ""

# # Function to Ask Predefined Questions
# def ask_predefined_questions():
#     user_responses = {}
#     for question in predefined_questions:
#         print(f"\nðŸ¤– AI: {question}")
#         user_response = input("Your answer: ").strip()
#         user_responses[question] = user_response
#     return user_responses

# # Function to Generate Response Using Retrieval-Augmented Generation
# def generate_rag_response(user_input):
#     # Get relevant information from vector database
#     relevant_info = get_relevant_info(user_input)
    
#     # Create a prompt that includes the retrieved information
#     rag_prompt = f"""
#     You are a knowledgeable mortgage advisor with expertise in UK mortgages, home loans, and property financing.
    
#     Relevant information from our knowledge base:
#     {relevant_info}
    
#     User's question: {user_input}
    
#     Based on the relevant information provided above, please give a comprehensive, detailed, and informative answer to the user's question.
#     Include specific details like typical interest rates, down payment percentages, loan terms, or requirements when relevant.
#     Avoid using markdown symbols like ** or *. Provide the answer in plain text.
#     If the information is not available in the knowledge base, provide general mortgage advice but be honest about limitations.
#     """
    
#     # Generate response using the model with RAG
#     response = llm.invoke([HumanMessage(content=rag_prompt)])
#     return response.content

# # Function to Generate Summary Using the Model
# def generate_summary(user_responses):
#     # Combine questions and answers into a prompt for the model
#     qa_pairs = "\n".join([f"Q: {q}\nA: {a}" for q, a in user_responses.items()])
    
#     # Prompt for the model to generate a summary
#     summary_prompt = f"""
#     You are a helpful mortgage advisor. Below are the questions and answers provided by the user. 
#     Please summarize the information in a clear, concise, and conversational way. Avoid repeating the same information multiple times.
#     Provide any relevant advice or next steps.

#     Questions and Answers:
#     {qa_pairs}

#     Summary:
#     """
    
#     # Generate summary using the model
#     summary_response = llm.invoke([HumanMessage(content=summary_prompt)])
#     return summary_response.content

# # Chat Memory Storage
# chat_history = []

# # Chatbot Interaction
# print("\nðŸš€ Welcome! Your AI Mortgage Advisor is ready. Ask me anything!")

# chat_active = True
# user_data = {}
# last_message = ""

# while chat_active:
#     user_input = input("\nYour message: ").strip()
    
#     if not user_input:
#         continue  # Skip empty input
    
#     if user_input.lower() in ["exit", "quit", "close"]:
#         print("âœ… Thank you for chatting! It was great talking to you. Have a wonderful day! ðŸ˜Š")
#         break  # Exit the chat
    
#     # Prevent duplicate messages
#     if user_input == last_message:
#         continue
#     last_message = user_input
    
#     # Check what type of query this is
#     query_type = is_mortgage_related(user_input)
    
#     # Handle based on query type
#     if query_type == "application":
#         # Full mortgage application process
#         print("\nðŸ¤– AI: Sure! I can help you with your mortgage application. Let me ask you a few questions to get started.")
#         user_data = ask_predefined_questions()
        
#         # Generate Summary Using the Model
#         print("\nðŸ¤– AI: Thank you for providing the information! Generating a summary for you...")
#         summary = generate_summary(user_data)
        
#         # Display Summary to the User
#         print(f"\nðŸ¤– AI: Here's a summary based on your answers:\n{summary}")
        
#         # Ask if they want to continue or exit
#         print("\nðŸ¤– AI: Would you like to continue chatting or exit? (Type 'continue' or 'exit')")
#         continue_choice = input("Your choice: ").strip().lower()
#         if continue_choice == "exit":
#             print("âœ… Thank you for chatting! It was great talking to you. Have a wonderful day! ðŸ˜Š")
#             break
    
#     elif query_type == "information":
#         # Mortgage information query - use RAG
#         response_text = generate_rag_response(user_input)
        
#         chat_history.append(HumanMessage(content=user_input))
#         chat_history.append(AIMessage(content=response_text))
        
#         print(f"\nðŸ¤– AI: {response_text}")
    
#     else:
#         # General chatbot interaction
#         general_prompt = f"""
#         You are a friendly and engaging mortgage advisor. Respond naturally and conversationally like a human. 
#         Avoid using markdown symbols or unnecessary formatting. Provide the answer in plain text.
#         Here's the user's message: '{user_input}'
#         """
#         general_response = llm.invoke([HumanMessage(content=general_prompt)])
#         response_text = general_response.content
        
#         chat_history.append(HumanMessage(content=user_input))
#         chat_history.append(AIMessage(content=response_text))
        
#         print(f"\nðŸ¤– AI: {response_text}")